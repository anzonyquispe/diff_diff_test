{
  "hash": "95097a6e31f40192330fb41541b61b6f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"R Package Analysis\"\n---\n\n\n\n\n# R Packages for Staggered DiD\n\nThis chapter benchmarks four major R packages for difference-in-differences with staggered treatment adoption.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Load the simulated data\npanel <- readRDS(\"sim_data.rds\")\n\ncat(\"Data loaded:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData loaded:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Observations:\", format(nrow(panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nObservations: 10,000,000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Units:\", format(length(unique(panel$id)), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnits: 1,000,000 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate true overall ATT for comparison\ntrue_overall_att <- mean(panel$tau_gt[panel$treated])\ncat(\"True overall ATT:\", round(true_overall_att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue overall ATT: 1.5869 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Initialize results storage\nresults <- list()\n```\n:::\n\n\n\n\n## 1. Callaway & Sant'Anna (`did` package)\n\nThe `did` package implements the method from Callaway & Sant'Anna (2021), estimating group-time average treatment effects and aggregating them.\n\n**Method**: Doubly-robust estimation combining outcome regression and propensity score weighting.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(did)\n\ncat(\"Running did::att_gt()...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning did::att_gt()...\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"This may take several minutes with 1M units.\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThis may take several minutes with 1M units.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Time the estimation\nstart_time <- Sys.time()\n\n# Estimate group-time ATTs\n# Using subset for large data (full data may require significant memory)\nout_cs <- att_gt(\n  yname = \"y\",\n  gname = \"first_treat\",\n  idname = \"id\",\n  tname = \"year\",\n  data = panel,\n  control_group = \"nevertreated\",\n  est_method = \"dr\",  # doubly robust\n  base_period = \"universal\"\n)\n\ncs_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n\ncat(\"\\nExecution time:\", round(cs_time, 2), \"seconds\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nExecution time: 31.49 seconds\n```\n\n\n:::\n\n```{.r .cell-code}\n# Aggregate to overall ATT\nagg_cs <- aggte(out_cs, type = \"simple\")\ncat(\"\\nOverall ATT estimate:\", round(agg_cs$overall.att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nOverall ATT estimate: 1.5846 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Standard error:\", round(agg_cs$overall.se, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard error: 0.0019 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATT:\", round(true_overall_att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATT: 1.5869 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Event study aggregation\nes_cs <- aggte(out_cs, type = \"dynamic\")\n\nresults$did <- list(\n  package = \"did\",\n  method = \"Callaway & Sant'Anna\",\n  time = cs_time,\n  att = agg_cs$overall.att,\n  se = agg_cs$overall.se,\n  event_study = es_cs\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot event study\nggdid(es_cs) +\n  labs(title = \"did package: Event Study\",\n       subtitle = paste(\"Execution time:\", round(cs_time, 1), \"seconds\"))\n```\n\n::: {.cell-output-display}\n![Event study: Callaway & Sant'Anna (did package)](r_analysis_files/figure-html/did-plot-1.png){width=672}\n:::\n:::\n\n\n\n\n## 2. de Chaisemartin & D'Haultfoeuille (`DIDmultiplegtDYN`)\n\nThe `DIDmultiplegtDYN` package implements the method from de Chaisemartin & D'Haultfoeuille, robust to heterogeneous treatment effects.\n\n**Method**: Comparing switchers to non-switchers at each period.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check if package is available\nif (requireNamespace(\"DIDmultiplegtDYN\", quietly = TRUE)) {\n  library(DIDmultiplegtDYN)\n  library(dplyr)  # for pipe operator\n\n  cat(\"Running DIDmultiplegtDYN::did_multiplegt_dyn()...\\n\")\n  cat(\"This estimator can be slow with large datasets.\\n\\n\")\n\n  # Prepare data - DIDmultiplegtDYN needs treatment as binary\n  panel_dcdh <- panel %>%\n    mutate(D = as.integer(treated)) %>%\n    select(id, year, y, D)\n\n  start_time <- Sys.time()\n\n  # Note: For very large datasets, this may require sampling\n  # The package is computationally intensive\n  tryCatch({\n    out_dcdh <- did_multiplegt_dyn(\n      df = panel_dcdh,\n      outcome = \"y\",\n      group = \"id\",\n      time = \"year\",\n      treatment = \"D\",\n      effects = 5,  # Number of event-study effects\n      placebo = 3,  # Number of pre-treatment placebos\n      cluster = \"id\",\n      graph_off = TRUE\n    )\n\n    dcdh_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n\n    cat(\"\\nExecution time:\", round(dcdh_time, 2), \"seconds\\n\")\n    print(summary(out_dcdh))\n\n    # Extract ATT from results$ATE\n    dcdh_att <- out_dcdh$results$ATE\n\n    cat(\"\\nAverage Total Effect (ATT):\", round(dcdh_att, 4), \"\\n\")\n    cat(\"True ATT:\", round(true_overall_att, 4), \"\\n\")\n\n    results$didmultiplegt <- list(\n      package = \"DIDmultiplegtDYN\",\n      method = \"de Chaisemartin & D'Haultfoeuille\",\n      time = dcdh_time,\n      att = dcdh_att,\n      output = out_dcdh\n    )\n  }, error = function(e) {\n    cat(\"Error running DIDmultiplegtDYN:\", e$message, \"\\n\")\n    cat(\"This package may have memory constraints with 1M observations.\\n\")\n    cat(\"Consider using a subsample for this estimator.\\n\")\n\n    results$didmultiplegt <<- list(\n      package = \"DIDmultiplegtDYN\",\n      method = \"de Chaisemartin & D'Haultfoeuille\",\n      time = NA,\n      error = e$message\n    )\n  })\n\n} else {\n  cat(\"Package DIDmultiplegtDYN not installed.\\n\")\n  cat(\"Install with: install.packages('DIDmultiplegtDYN')\\n\")\n\n  results$didmultiplegt <- list(\n    package = \"DIDmultiplegtDYN\",\n    method = \"de Chaisemartin & D'Haultfoeuille\",\n    time = NA,\n    error = \"Package not installed\"\n  )\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning DIDmultiplegtDYN::did_multiplegt_dyn()...\nThis estimator can be slow with large datasets.\n\nError running DIDmultiplegtDYN: vector memory limit of 36.0 Gb reached, see mem.maxVSize() \nThis package may have memory constraints with 1M observations.\nConsider using a subsample for this estimator.\n```\n\n\n:::\n:::\n\n\n\n\n### Alternative: Using a subsample\n\nDue to computational constraints, we may need to use a subsample:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (requireNamespace(\"DIDmultiplegtDYN\", quietly = TRUE) &&\n    (is.null(results$didmultiplegt$time) || is.na(results$didmultiplegt$time))) {\n\n  library(DIDmultiplegtDYN)\n  library(dplyr)  # for pipe operator\n\n  cat(\"Running DIDmultiplegtDYN on 10% subsample...\\n\")\n\n  # Sample 10% of units\n  set.seed(123)\n  sample_ids <- sample(unique(panel$id), size = 100000)\n  panel_sample <- panel %>%\n    filter(id %in% sample_ids) %>%\n    mutate(D = as.integer(treated)) %>%\n    select(id, year, y, D)\n\n  cat(\"Subsample size:\", format(nrow(panel_sample), big.mark = \",\"), \"\\n\\n\")\n\n  start_time <- Sys.time()\n\n  tryCatch({\n    out_dcdh_sample <- did_multiplegt_dyn(\n      df = panel_sample,\n      outcome = \"y\",\n      group = \"id\",\n      time = \"year\",\n      treatment = \"D\",\n      effects = 5,\n      placebo = 3,\n      cluster = \"id\",\n      graph_off = TRUE\n    )\n\n    dcdh_time_sample <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n\n    cat(\"\\nExecution time (10% sample):\", round(dcdh_time_sample, 2), \"seconds\\n\")\n    cat(\"Estimated full data time:\", round(dcdh_time_sample * 10, 2), \"seconds\\n\")\n    print(summary(out_dcdh_sample))\n\n    # Extract ATT from results$ATE\n    dcdh_att_sample <- out_dcdh_sample$results$ATE\n\n    cat(\"\\nAverage Total Effect (ATT):\", round(dcdh_att_sample, 4), \"\\n\")\n    cat(\"True ATT:\", round(true_overall_att, 4), \"\\n\")\n\n    results$didmultiplegt_sample <- list(\n      package = \"DIDmultiplegtDYN\",\n      method = \"de Chaisemartin & D'Haultfoeuille (10% sample)\",\n      time = dcdh_time_sample,\n      att = dcdh_att_sample,\n      estimated_full_time = dcdh_time_sample * 10,\n      output = out_dcdh_sample\n    )\n  }, error = function(e) {\n    cat(\"Error:\", e$message, \"\\n\")\n  })\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning DIDmultiplegtDYN on 10% subsample...\nSubsample size: 1,000,000 \n\n\nExecution time (10% sample): 76.09 seconds\nEstimated full data time: 760.9 seconds\n\n----------------------------------------------------------------------\n       Estimation of treatment effects: Event-study effects\n----------------------------------------------------------------------\n             Estimate SE      LB CI   UB CI   N       Switchers\nEffect_1     1.23956  0.00624 1.22734 1.25179 279,385 70,318   \nEffect_2     1.35506  0.00621 1.34288 1.36723 279,385 70,318   \nEffect_3     1.49808  0.00708 1.48420 1.51196 189,344 60,368   \nEffect_4     1.59630  0.00709 1.58241 1.61020 189,344 60,368   \nEffect_5     1.79333  0.00890 1.77589 1.81077 109,652 40,338   \n\nTest of joint nullity of the effects : p-value = 0.0000\n----------------------------------------------------------------------\n    Average cumulative (total) effect per treatment unit\n----------------------------------------------------------------------\n Estimate        SE     LB CI     UB CI         N Switchers \n  1.46362   0.00528   1.45327   1.47398   719,844   301,710 \nAverage number of time periods over which a treatment effect is accumulated: 2.7683\n\n----------------------------------------------------------------------\n     Testing the parallel trends and no anticipation assumptions\n----------------------------------------------------------------------\n             Estimate SE      LB CI    UB CI    N       Switchers\nPlacebo_1    -0.00871 0.00624 -0.02094 0.00353  279,385 70,318   \nPlacebo_2    -0.01505 0.00749 -0.02974 -0.00037 179,385 50,409   \nPlacebo_3    -0.00406 0.00887 -0.02144 0.01333  109,773 40,459   \n\nTest of joint nullity of the placebos : p-value = 0.2133\n\n\nThe development of this package was funded by the European Union.\nERC REALLYCREDIBLE - GA N. 101043899\nNULL\n\nAverage Total Effect (ATT): 1.4636 0.0053 1.4533 1.474 719844 301710 719844 301710 \nTrue ATT: 1.5869 \n```\n\n\n:::\n:::\n\n\n\n\n## 3. Sun & Abraham (`fixest::sunab`)\n\nThe `fixest` package provides the interaction-weighted estimator from Sun & Abraham (2021) through the `sunab()` function.\n\n**Method**: Cohort-specific coefficients with clean controls.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest)\n\ncat(\"Running fixest::feols() with sunab()...\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning fixest::feols() with sunab()...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create cohort variable for sunab\npanel_sa <- panel %>%\n  mutate(\n    cohort = ifelse(first_treat == 0, Inf, first_treat),  # Never-treated = Inf\n    rel_time = ifelse(first_treat == 0, -1000, year - first_treat)  # Relative time\n  )\n\nstart_time <- Sys.time()\n\n# Sun & Abraham estimation using sunab\nout_sa <- feols(\n  y ~ sunab(cohort, year) | id + year,\n  data = panel_sa,\n  cluster = ~id\n)\n\nsa_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n\ncat(\"Execution time:\", round(sa_time, 2), \"seconds\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExecution time: 27.16 seconds\n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary\nsummary(out_sa, agg = \"ATT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: y\nObservations: 10,000,000\nFixed-effects: id: 1,000,000,  year: 10\nStandard-errors: Clustered (id) \n    Estimate Std. Error t value  Pr(>|t|)    \nATT  1.58456   0.001775 892.853 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.948956     Adj. R2: 0.636526\n                 Within R2: 0.14887 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Get aggregated ATT - fixest aggregate returns different structure\nagg_sa <- summary(out_sa, agg = \"ATT\")\n\n# Extract ATT from the aggregated coefficients\nsa_coefs <- coef(agg_sa)\nsa_ses <- se(agg_sa)\n\n# Filter to post-treatment effects (event time >= 0) and compute mean\npost_idx <- grep(\"^year::\", names(sa_coefs))\nif (length(post_idx) > 0) {\n  # Get event times from coefficient names\n  event_times <- as.numeric(gsub(\"year::\", \"\", names(sa_coefs)[post_idx]))\n  post_treatment <- event_times >= 0\n  sa_att <- mean(sa_coefs[post_idx][post_treatment], na.rm = TRUE)\n  sa_se <- mean(sa_ses[post_idx][post_treatment], na.rm = TRUE)\n} else {\n  sa_att <- mean(sa_coefs, na.rm = TRUE)\n  sa_se <- mean(sa_ses, na.rm = TRUE)\n}\n\ncat(\"\\nOverall ATT estimate (post-treatment avg):\", round(sa_att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nOverall ATT estimate (post-treatment avg): 1.5846 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATT:\", round(true_overall_att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATT: 1.5869 \n```\n\n\n:::\n\n```{.r .cell-code}\nresults$sunab <- list(\n  package = \"fixest\",\n  method = \"Sun & Abraham (sunab)\",\n  time = sa_time,\n  att = sa_att,\n  se = sa_se,\n  model = out_sa\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Event study plot\niplot(out_sa,\n      main = paste(\"fixest::sunab Event Study\\nExecution time:\",\n                   round(sa_time, 1), \"seconds\"))\n```\n\n::: {.cell-output-display}\n![Event study: Sun & Abraham (fixest::sunab)](r_analysis_files/figure-html/sunab-plot-1.png){width=672}\n:::\n:::\n\n\n\n\n## 4. Imputation Estimator (`didimputation`)\n\nThe `didimputation` package implements the imputation approach from Borusyak, Jaravel & Spiess (2024).\n\n**Method**: Impute counterfactual outcomes for treated units using never-treated/not-yet-treated.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (requireNamespace(\"didimputation\", quietly = TRUE)) {\n  library(didimputation)\n\n  cat(\"Running didimputation::did_imputation()...\\n\\n\")\n\n  # Prepare data\n  panel_imp <- panel %>%\n    mutate(\n      first_treat = ifelse(first_treat == 0, NA_integer_, first_treat),\n      rel_time = ifelse(is.na(first_treat), NA_integer_, year - first_treat)\n    )\n\n  start_time <- Sys.time()\n\n  tryCatch({\n    out_imp <- did_imputation(\n      data = panel_imp,\n      yname = \"y\",\n      gname = \"first_treat\",\n      tname = \"year\",\n      idname = \"id\",\n      first_stage = ~ 0 | id + year,\n      horizon = TRUE,\n      pretrends = TRUE\n    )\n\n    imp_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n\n    cat(\"Execution time:\", round(imp_time, 2), \"seconds\\n\\n\")\n    print(out_imp)\n\n    # Extract overall ATT\n    att_rows <- out_imp$term >= 0\n    overall_att_imp <- mean(out_imp$estimate[att_rows])\n\n    cat(\"\\nOverall ATT (post-treatment avg):\", round(overall_att_imp, 4), \"\\n\")\n    cat(\"True ATT:\", round(true_overall_att, 4), \"\\n\")\n\n    results$didimputation <- list(\n      package = \"didimputation\",\n      method = \"Borusyak, Jaravel & Spiess\",\n      time = imp_time,\n      att = overall_att_imp,\n      output = out_imp\n    )\n  }, error = function(e) {\n    cat(\"Error running didimputation:\", e$message, \"\\n\")\n    results$didimputation <<- list(\n      package = \"didimputation\",\n      method = \"Borusyak, Jaravel & Spiess\",\n      time = NA,\n      error = e$message\n    )\n  })\n\n} else {\n  cat(\"Package didimputation not installed.\\n\")\n  cat(\"Install with: install.packages('didimputation')\\n\")\n\n  results$didimputation <- list(\n    package = \"didimputation\",\n    method = \"Borusyak, Jaravel & Spiess\",\n    time = NA,\n    error = \"Package not installed\"\n  )\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning didimputation::did_imputation()...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError running didimputation: LU factorization of .gCMatrix failed: out of memory or near-singular \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(results$didimputation$output)) {\n  out_imp <- results$didimputation$output\n  imp_time <- results$didimputation$time\n\n  ggplot(out_imp, aes(x = term, y = estimate)) +\n    geom_point() +\n    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_vline(xintercept = -0.5, linetype = \"dashed\", color = \"red\") +\n    labs(\n      x = \"Event Time\",\n      y = \"Estimate\",\n      title = \"didimputation Event Study\",\n      subtitle = paste(\"Execution time:\", round(imp_time, 1), \"seconds\")\n    ) +\n    theme_minimal()\n}\n```\n:::\n\n\n\n\n## 5. Traditional TWFE (Biased Baseline)\n\nFor comparison, let's also run traditional two-way fixed effects, which is known to be biased with heterogeneous effects:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest)\n\ncat(\"Running traditional TWFE for comparison...\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning traditional TWFE for comparison...\n```\n\n\n:::\n\n```{.r .cell-code}\nstart_time <- Sys.time()\n\nout_twfe <- feols(\n  y ~ treated | id + year,\n  data = panel,\n  cluster = ~id\n)\n\ntwfe_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n\ncat(\"Execution time:\", round(twfe_time, 2), \"seconds\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExecution time: 1.1 seconds\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(out_twfe)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: y\nObservations: 10,000,000\nFixed-effects: id: 1,000,000,  year: 10\nStandard-errors: Clustered (id) \n            Estimate Std. Error t value  Pr(>|t|)    \ntreatedTRUE  1.32861   0.001155 1150.25 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.958966     Adj. R2: 0.628819\n                 Within R2: 0.130818\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nTWFE ATT estimate:\", round(coef(out_twfe), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTWFE ATT estimate: 1.3286 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATT:\", round(true_overall_att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATT: 1.5869 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Bias:\", round(coef(out_twfe) - true_overall_att, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBias: -0.2583 \n```\n\n\n:::\n\n```{.r .cell-code}\nresults$twfe <- list(\n  package = \"fixest\",\n  method = \"Traditional TWFE (biased)\",\n  time = twfe_time,\n  att = coef(out_twfe),\n  se = se(out_twfe)\n)\n```\n:::\n\n\n\n\n## R Results Summary\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create summary table\nsummary_df <- data.frame(\n  Package = character(),\n  Method = character(),\n  Time_seconds = numeric(),\n  ATT_estimate = numeric(),\n  True_ATT = numeric(),\n  Bias = numeric(),\n  stringsAsFactors = FALSE\n)\n\nfor (name in names(results)) {\n  r <- results[[name]]\n  att <- if (!is.null(r$att)) r$att else NA\n  summary_df <- rbind(summary_df, data.frame(\n    Package = r$package,\n    Method = r$method,\n    Time_seconds = ifelse(is.null(r$time), NA, r$time),\n    ATT_estimate = att,\n    True_ATT = true_overall_att,\n    Bias = ifelse(is.na(att), NA, att - true_overall_att),\n    stringsAsFactors = FALSE\n  ))\n}\n\nknitr::kable(summary_df, digits = 4,\n             caption = \"R Package Comparison Summary\")\n```\n\n::: {.cell-output-display}\n\n\nTable: R Package Comparison Summary\n\n|            |Package          |Method                                         | Time_seconds| ATT_estimate| True_ATT|    Bias|\n|:-----------|:----------------|:----------------------------------------------|------------:|------------:|--------:|-------:|\n|1           |did              |Callaway & Sant'Anna                           |      30.0508|       1.5846|   1.5869| -0.0023|\n|2           |DIDmultiplegtDYN |de Chaisemartin & D'Haultfoeuille              |           NA|           NA|   1.5869|      NA|\n|3           |DIDmultiplegtDYN |de Chaisemartin & D'Haultfoeuille (10% sample) |      71.3493|           NA|   1.5869|      NA|\n|4           |fixest           |Sun & Abraham (sunab)                          |      25.4929|       1.5846|   1.5869| -0.0023|\n|5           |didimputation    |Borusyak, Jaravel & Spiess                     |           NA|           NA|   1.5869|      NA|\n|treatedTRUE |fixest           |Traditional TWFE (biased)                      |       0.9361|       1.3286|   1.5869| -0.2583|\n\n\n:::\n\n```{.r .cell-code}\n# Save results for comparison chapter\nsaveRDS(results, \"r_results.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to valid times\ntiming_df <- summary_df %>%\n  filter(!is.na(Time_seconds))\n\nggplot(timing_df, aes(x = reorder(Package, Time_seconds), y = Time_seconds)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    x = \"Package\",\n    y = \"Execution Time (seconds)\",\n    title = \"R Package Execution Times\",\n    subtitle = paste(\"Dataset:\", format(nrow(panel), big.mark = \",\"), \"observations\")\n  ) +\n  theme_minimal() +\n  geom_text(aes(label = round(Time_seconds, 1)), hjust = -0.1)\n```\n\n::: {.cell-output-display}\n![Execution time comparison (R packages)](r_analysis_files/figure-html/r-timing-plot-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}