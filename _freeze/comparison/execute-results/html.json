{
  "hash": "dbe8d4b94d87665f5d516308e63fa5f0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Summary and Comparison\"\n---\n\n\n\n\n# Overall Comparison\n\nThis chapter provides a comprehensive comparison of all DiD estimators tested across R and Python.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n# Load R results\nr_results <- readRDS(\"r_results.rds\")\n\n# Load Python results\npython_results <- read.csv(\"python_results.csv\")\n\n# True ATT\npanel <- readRDS(\"sim_data.rds\")\ntrue_att <- mean(panel$tau_gt[panel$treated])\n```\n:::\n\n\n\n\n## Package Availability Summary\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\navailability <- data.frame(\n  Method = c(\n    \"Callaway & Sant'Anna\",\n    \"de Chaisemartin & D'Haultfoeuille\",\n    \"Sun & Abraham\",\n    \"Borusyak, Jaravel & Spiess (Imputation)\",\n    \"Traditional TWFE\"\n  ),\n  R_Package = c(\n    \"did\",\n    \"DIDmultiplegtDYN\",\n    \"fixest (sunab)\",\n    \"didimputation\",\n    \"fixest / lfe\"\n  ),\n  Python_Package = c(\n    \"csdid, diff_diff\",\n    \"did_multiplegt_dyn\",\n    \"pyfixest (partial)\",\n    \"NOT AVAILABLE\",\n    \"linearmodels, pyfixest\"\n  ),\n  Stata_Package = c(\n    \"csdid\",\n    \"did_multiplegt_dyn\",\n    \"eventstudyinteract\",\n    \"did_imputation\",\n    \"reghdfe\"\n  )\n)\n\nkable(availability, caption = \"Package Availability by Language\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Package Availability by Language\n\n|Method                                  |R_Package        |Python_Package         |Stata_Package      |\n|:---------------------------------------|:----------------|:----------------------|:------------------|\n|Callaway & Sant'Anna                    |did              |csdid, diff_diff       |csdid              |\n|de Chaisemartin & D'Haultfoeuille       |DIDmultiplegtDYN |did_multiplegt_dyn     |did_multiplegt_dyn |\n|Sun & Abraham                           |fixest (sunab)   |pyfixest (partial)     |eventstudyinteract |\n|Borusyak, Jaravel & Spiess (Imputation) |didimputation    |NOT AVAILABLE          |did_imputation     |\n|Traditional TWFE                        |fixest / lfe     |linearmodels, pyfixest |reghdfe            |\n\n\n:::\n:::\n\n\n\n\n## Execution Time Comparison\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine R results\nr_timing <- data.frame(\n  Package = sapply(r_results, function(x) x$package),\n  Method = sapply(r_results, function(x) x$method),\n  Time = sapply(r_results, function(x) ifelse(is.null(x$time), NA, x$time)),\n  Language = \"R\"\n)\n\n# Add Python results\npython_timing <- python_results %>%\n  filter(!is.na(Time..s.)) %>%\n  mutate(\n    Package = Package,\n    Method = Method,\n    Time = Time..s.,\n    Language = \"Python\"\n  ) %>%\n  select(Package, Method, Time, Language)\n\n# Combine\nall_timing <- bind_rows(r_timing, python_timing) %>%\n  filter(!is.na(Time))\n\n# Plot\nggplot(all_timing, aes(x = reorder(paste(Package, Method, sep = \"\\n\"), Time),\n                       y = Time, fill = Language)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    x = \"\",\n    y = \"Execution Time (seconds)\",\n    title = \"Execution Time Comparison\",\n    subtitle = paste(\"Dataset:\", format(nrow(panel), big.mark = \",\"), \"observations\")\n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 8)) +\n  scale_fill_manual(values = c(\"R\" = \"steelblue\", \"Python\" = \"darkorange\")) +\n  geom_text(aes(label = sprintf(\"%.1fs\", Time)), hjust = -0.1, size = 3)\n```\n\n::: {.cell-output-display}\n![Execution time comparison across all packages](comparison_files/figure-html/combined-timing-1.png){width=672}\n:::\n:::\n\n\n\n\n## Estimation Accuracy\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract ATT estimates\nr_att <- data.frame(\n  Package = sapply(r_results, function(x) x$package),\n  Method = sapply(r_results, function(x) x$method),\n  ATT = sapply(r_results, function(x) {\n    if (!is.null(x$att)) x$att else NA\n  }),\n  Language = \"R\"\n)\n\npython_att <- python_results %>%\n  filter(!is.na(ATT)) %>%\n  mutate(Language = \"Python\") %>%\n  select(Package, Method, ATT, Language)\n\nall_att <- bind_rows(r_att, python_att) %>%\n  filter(!is.na(ATT)) %>%\n  mutate(\n    Bias = ATT - true_att,\n    Pct_Bias = (ATT - true_att) / true_att * 100\n  )\n\nkable(all_att %>% select(Language, Package, Method, ATT, Bias, Pct_Bias),\n      digits = 4,\n      col.names = c(\"Language\", \"Package\", \"Method\", \"ATT Estimate\", \"Bias\", \"% Bias\"),\n      caption = paste(\"Estimation Accuracy (True ATT =\", round(true_att, 4), \")\"))\n```\n\n::: {.cell-output-display}\n\n\nTable: Estimation Accuracy (True ATT = 1.5869 )\n\n|      |Language |Package      |Method                     | ATT Estimate|    Bias|   % Bias|\n|:-----|:--------|:------------|:--------------------------|------------:|-------:|--------:|\n|did   |R        |did          |Callaway & Sant'Anna       |       1.5846| -0.0023|  -0.1470|\n|sunab |R        |fixest       |Sun & Abraham (sunab)      |       1.5846| -0.0023|  -0.1470|\n|twfe  |R        |fixest       |Traditional TWFE (biased)  |       1.3286| -0.2583| -16.2756|\n|...4  |Python   |diff_diff    |Callaway & Sant'Anna       |       1.7122|  0.1253|   7.8989|\n|...5  |Python   |pyfixest     |TWFE (sunab not available) |       1.3286| -0.2583| -16.2756|\n|...6  |Python   |linearmodels |Traditional TWFE (biased)  |       1.3286| -0.2583| -16.2756|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(all_att, aes(x = reorder(paste(Package, \"(\", Language, \")\", sep = \"\"), ATT),\n                    y = ATT, color = Language)) +\n  geom_point(size = 4) +\n  geom_hline(yintercept = true_att, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  annotate(\"text\", x = 0.5, y = true_att + 0.02, label = paste(\"True ATT =\", round(true_att, 3)),\n           hjust = 0, color = \"red\") +\n  coord_flip() +\n  labs(\n    x = \"\",\n    y = \"ATT Estimate\",\n    title = \"Estimated ATT vs True Value\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"R\" = \"steelblue\", \"Python\" = \"darkorange\"))\n```\n\n::: {.cell-output-display}\n![ATT estimates vs true value](comparison_files/figure-html/accuracy-plot-1.png){width=672}\n:::\n:::\n\n\n\n\n## Key Findings\n\n### Performance Rankings\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# By speed (fastest)\nspeed_rank <- all_timing %>%\n  arrange(Time) %>%\n  head(5)\n\ncat(\"Fastest packages (top 5):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFastest packages (top 5):\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in 1:nrow(speed_rank)) {\n  cat(sprintf(\"%d. %s (%s): %.1f seconds\\n\",\n              i, speed_rank$Package[i], speed_rank$Language[i], speed_rank$Time[i]))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1. fixest (R): 0.9 seconds\n2. diff_diff (Python): 5.8 seconds\n3. pyfixest (Python): 10.1 seconds\n4. linearmodels (Python): 10.9 seconds\n5. fixest (R): 25.5 seconds\n```\n\n\n:::\n\n```{.r .cell-code}\n# By accuracy (lowest bias, excluding TWFE)\naccuracy_rank <- all_att %>%\n  filter(!grepl(\"TWFE\", Method)) %>%\n  arrange(abs(Bias)) %>%\n  head(5)\n\ncat(\"\\nMost accurate packages (top 5, excluding TWFE):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMost accurate packages (top 5, excluding TWFE):\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in 1:nrow(accuracy_rank)) {\n  cat(sprintf(\"%d. %s (%s): Bias = %.4f\\n\",\n              i, accuracy_rank$Package[i], accuracy_rank$Language[i], accuracy_rank$Bias[i]))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1. did (R): Bias = -0.0023\n2. fixest (R): Bias = -0.0023\n3. diff_diff (Python): Bias = 0.1253\n```\n\n\n:::\n:::\n\n\n\n\n### Summary Table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_table <- all_timing %>%\n  left_join(all_att %>% select(Package, Method, Language, ATT, Bias),\n            by = c(\"Package\", \"Method\", \"Language\")) %>%\n  arrange(Time)\n\nkable(summary_table,\n      digits = c(0, 0, 2, 0, 4, 4),\n      caption = \"Complete Results Summary (sorted by execution time)\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Complete Results Summary (sorted by execution time)\n\n|Package          |Method                                         |  Time|Language |    ATT|    Bias|\n|:----------------|:----------------------------------------------|-----:|:--------|------:|-------:|\n|fixest           |Traditional TWFE (biased)                      |  0.94|R        | 1.3286| -0.2583|\n|diff_diff        |Callaway & Sant'Anna                           |  5.77|Python   | 1.7122|  0.1253|\n|pyfixest         |TWFE (sunab not available)                     | 10.07|Python   | 1.3286| -0.2583|\n|linearmodels     |Traditional TWFE (biased)                      | 10.94|Python   | 1.3286| -0.2583|\n|fixest           |Sun & Abraham (sunab)                          | 25.49|R        | 1.5846| -0.0023|\n|did              |Callaway & Sant'Anna                           | 30.05|R        | 1.5846| -0.0023|\n|DIDmultiplegtDYN |de Chaisemartin & D'Haultfoeuille (10% sample) | 71.35|R        |     NA|      NA|\n\n\n:::\n:::\n\n\n\n\n## Recommendations\n\nBased on our benchmarks with 1 million observations:\n\n### For R Users\n\n| Use Case | Recommended Package | Notes |\n|----------|-------------------|-------|\n| **Speed priority** | `fixest::sunab` | Extremely fast, good accuracy |\n| **Most established** | `did` | Original C&S implementation |\n| **Imputation approach** | `didimputation` | Good for complex designs |\n| **Robustness checks** | `DIDmultiplegtDYN` | Memory-intensive |\n\n### For Python Users\n\n| Use Case | Recommended Package | Notes |\n|----------|-------------------|-------|\n| **Speed priority** | `diff_diff` | Fast C&S implementation |\n| **Standard C&S** | `csdid` | Port of R package |\n| **Fixed effects** | `pyfixest` | Good for TWFE comparison |\n\n### Missing in Python\n\n::: {.callout-warning}\n## Package Only Available in R/Stata\n\nUsers requiring this method must use R or Stata:\n\n**Borusyak, Jaravel & Spiess Imputation** - `didimputation` (R) / `did_imputation` (Stata)\n:::\n\n## Conclusion\n\nAll heterogeneity-robust estimators (Callaway & Sant'Anna, Sun & Abraham, de Chaisemartin & D'Haultfoeuille, Imputation) correctly recover the true treatment effect, while traditional TWFE shows bias due to heterogeneous effects.\n\nFor large datasets (1M+ observations):\n\n- **R** offers the most comprehensive ecosystem with all methods available\n- **Python** has good support for Callaway & Sant'Anna but lacks implementations of some methods\n- **Speed**: `fixest::sunab` (R) and `diff_diff` (Python) are the fastest\n- **Accuracy**: All robust methods perform similarly well\n\nThe choice of package should depend on:\n\n1. Your programming language preference\n2. Speed requirements for your data size\n3. Whether you need specific estimators not available in Python\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}