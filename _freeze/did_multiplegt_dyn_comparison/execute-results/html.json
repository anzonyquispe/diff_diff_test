{
  "hash": "a0bd3feb9cf0e98be508997316c2cd3e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"did_multiplegt_dyn: Cross-Platform Comparison\"\n---\n\n\n\n\n\n# de Chaisemartin & D'Haultfoeuille Estimator Comparison\n\nThis chapter provides a comprehensive comparison of the `did_multiplegt_dyn` estimator across Stata, R (CRAN and Polars versions), and Python implementations, with a focus on **runtime performance**.\n\n## Overview\n\nThe `did_multiplegt_dyn` command estimates event-study Difference-in-Differences (DID) estimators in designs with:\n- Multiple groups and periods\n- Potentially non-binary treatment that may increase or decrease multiple times\n- Heterogeneous treatment effects across groups and time\n\n### Available Implementations\n\n| Platform | Package | Source | Optimization |\n|----------|---------|--------|--------------|\n| **Stata** | `did_multiplegt_dyn` | SSC | Reference implementation |\n| **R (CRAN)** | `DIDmultiplegtDYN` | CRAN | Standard R |\n| **R (Polars)** | `DIDmultiplegtDYNpolars` | GitHub/Local | Polars-optimized |\n| **Python** | `py-did-multiplegt-dyn` | PyPI | Pandas/NumPy |\n\n## Runtime Comparison\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(scales)\n\n# Set paths\nsave_path <- \"CX\"\n\n# Function to safely load CSV\nload_runtime <- function(file, platform) {\n  filepath <- file.path(save_path, file)\n  if (file.exists(filepath)) {\n    df <- read.csv(filepath)\n    df$Platform <- platform\n    return(df)\n  }\n  return(NULL)\n}\n\n# Load all runtime results\nruntime_stata <- load_runtime(\"runtime_stata.csv\", \"Stata\")\nruntime_r_cran <- load_runtime(\"runtime_R_cran.csv\", \"R_CRAN\")\nruntime_r_polars <- load_runtime(\"runtime_R_polars.csv\", \"R_Polars\")\nruntime_python <- load_runtime(\"runtime_python.csv\", \"Python\")\n\n# Combine all results\nall_runtimes <- bind_rows(\n  runtime_stata,\n  runtime_r_cran,\n  runtime_r_polars,\n  runtime_python\n)\n\nif (nrow(all_runtimes) > 0) {\n  cat(\"Runtime data loaded from\", sum(!sapply(list(runtime_stata, runtime_r_cran, runtime_r_polars, runtime_python), is.null)), \"platforms\\n\")\n  cat(\"Total observations:\", nrow(all_runtimes), \"\\n\")\n} else {\n  cat(\"No runtime data found. Please run the test scripts first:\\n\")\n  cat(\"  - Stata: CX/arXiv_replication.do\\n\")\n  cat(\"  - R CRAN: CX/test_did_multiplegt_dyn_cran.R\\n\")\n  cat(\"  - R Polars: CX/test_did_multiplegt_dyn_polars.R\\n\")\n  cat(\"  - Python: CX/test_did_multiplegt_dyn_python.py\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRuntime data loaded from 3 platforms\nTotal observations: 38 \n```\n\n\n:::\n:::\n\n\n\n\n\n### Runtime Summary Table\n\n\n\n\n\n::: {.cell tbl-cap='Runtime comparison across all platforms (seconds)'}\n\n```{.r .cell-code}\nif (nrow(all_runtimes) > 0) {\n  # Create pivot table\n  runtime_pivot <- all_runtimes %>%\n    select(Example, Model, Platform, Runtime_sec) %>%\n    pivot_wider(\n      names_from = Platform,\n      values_from = Runtime_sec,\n      values_fn = first\n    )\n\n  # Add speedup columns if we have both R versions\n  if (\"R_CRAN\" %in% names(runtime_pivot) && \"R_Polars\" %in% names(runtime_pivot)) {\n    runtime_pivot <- runtime_pivot %>%\n      mutate(\n        `Polars Speedup` = round(R_CRAN / R_Polars, 2)\n      )\n  }\n\n  kable(runtime_pivot, digits = 3, caption = \"Runtime in seconds by platform\")\n}\n```\n\n::: {.cell-output-display}\n\n\nTable: Runtime in seconds by platform\n\n|Example     |Model           | Stata| R_CRAN| R_Polars| Polars Speedup|\n|:-----------|:---------------|-----:|------:|--------:|--------------:|\n|Wagepan     |Baseline        | 0.685|  1.093|    1.769|           0.62|\n|Wagepan     |Placebos        | 0.825|  1.735|    2.381|           0.73|\n|Wagepan     |Normalized      | 0.846|  1.907|    2.388|           0.80|\n|Wagepan     |Controls        | 1.271|  3.492|    3.399|           1.03|\n|Wagepan     |Trends_Nonparam | 0.882|  1.660|    2.372|           0.70|\n|Wagepan     |Trends_Lin      | 2.946|  4.238|    9.611|           0.44|\n|Wagepan     |Cluster         | 0.896|  1.994|    2.949|           0.68|\n|Wagepan     |Same_Switchers  | 1.282|  1.957|    3.198|           0.61|\n|Wagepan     |Switchers_In    | 0.520|  0.837|    0.905|           0.92|\n|Wagepan     |Switchers_Out   | 0.503|  0.779|    1.079|           0.72|\n|Favara_Imbs |Baseline        |    NA|  0.005|    0.006|           0.88|\n|Deryugina   |Baseline        |    NA| 46.915|    6.948|           6.75|\n|Gentzkow    |Non_Normalized  |    NA|  0.000|    0.000|           1.20|\n|Gentzkow    |Normalized      |    NA|  0.000|    0.000|           1.15|\n\n\n:::\n:::\n\n\n\n\n\n### Wagepan Benchmark Results\n\nThe Wagepan dataset is our primary benchmark with 10 different test configurations.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (nrow(all_runtimes) > 0) {\n  wagepan_runtimes <- all_runtimes %>%\n    filter(Example == \"Wagepan\")\n\n  if (nrow(wagepan_runtimes) > 0) {\n    # Order models by complexity\n    model_order <- c(\"Baseline\", \"Placebos\", \"Normalized\", \"Controls\",\n                     \"Trends_Nonparam\", \"Trends_Lin\", \"Cluster\",\n                     \"Same_Switchers\", \"Switchers_In\", \"Switchers_Out\")\n\n    wagepan_runtimes$Model <- factor(wagepan_runtimes$Model, levels = model_order)\n\n    # Platform colors\n    platform_colors <- c(\n      \"Stata\" = \"#1f77b4\",\n      \"R_CRAN\" = \"#ff7f0e\",\n      \"R_Polars\" = \"#2ca02c\",\n      \"Python\" = \"#d62728\"\n    )\n\n    ggplot(wagepan_runtimes, aes(x = Model, y = Runtime_sec, fill = Platform)) +\n      geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.8) +\n      scale_fill_manual(values = platform_colors) +\n      theme_minimal() +\n      theme(\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n        legend.position = \"bottom\",\n        plot.title = element_text(size = 14, face = \"bold\")\n      ) +\n      labs(\n        title = \"Wagepan Dataset: Runtime by Test Configuration\",\n        subtitle = \"Lower is better\",\n        x = \"Test Configuration\",\n        y = \"Runtime (seconds)\",\n        fill = \"Platform\"\n      ) +\n      geom_text(\n        aes(label = round(Runtime_sec, 2)),\n        position = position_dodge(width = 0.9),\n        vjust = -0.5,\n        size = 2.5\n      )\n  }\n}\n```\n\n::: {.cell-output-display}\n![Wagepan dataset: Runtime comparison by test configuration](did_multiplegt_dyn_comparison_files/figure-html/wagepan-runtime-chart-1.png){width=960}\n:::\n:::\n\n\n\n\n\n### Speedup Analysis: R Polars vs R CRAN\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(runtime_r_cran) && !is.null(runtime_r_polars)) {\n  # Merge for comparison\n  comparison <- runtime_r_polars %>%\n    select(Example, Model, Runtime_Polars = Runtime_sec) %>%\n    left_join(\n      runtime_r_cran %>% select(Example, Model, Runtime_CRAN = Runtime_sec),\n      by = c(\"Example\", \"Model\")\n    ) %>%\n    mutate(\n      Speedup = Runtime_CRAN / Runtime_Polars,\n      Time_Saved_sec = Runtime_CRAN - Runtime_Polars,\n      Time_Saved_pct = (Runtime_CRAN - Runtime_Polars) / Runtime_CRAN * 100\n    ) %>%\n    filter(!is.na(Speedup))\n\n  if (nrow(comparison) > 0) {\n    # Summary statistics\n    cat(\"\\n=== R Polars vs R CRAN Speedup Summary ===\\n\\n\")\n    cat(\"Average speedup:\", round(mean(comparison$Speedup, na.rm = TRUE), 2), \"x\\n\")\n    cat(\"Maximum speedup:\", round(max(comparison$Speedup, na.rm = TRUE), 2), \"x\\n\")\n    cat(\"Minimum speedup:\", round(min(comparison$Speedup, na.rm = TRUE), 2), \"x\\n\")\n    cat(\"Total time saved:\", round(sum(comparison$Time_Saved_sec, na.rm = TRUE), 2), \"seconds\\n\")\n    cat(\"Average time saved per test:\", round(mean(comparison$Time_Saved_pct, na.rm = TRUE), 1), \"%\\n\")\n\n    # Speedup bar chart\n    comparison$Label <- paste(comparison$Example, comparison$Model, sep = \": \")\n\n    ggplot(comparison, aes(x = reorder(Label, Speedup), y = Speedup)) +\n      geom_bar(stat = \"identity\", fill = \"#2ca02c\", alpha = 0.8) +\n      geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n      coord_flip() +\n      theme_minimal() +\n      theme(\n        axis.text.y = element_text(size = 9),\n        plot.title = element_text(size = 14, face = \"bold\")\n      ) +\n      labs(\n        title = \"R Polars Speedup over R CRAN\",\n        subtitle = \"Values > 1 indicate Polars is faster (red line = parity)\",\n        x = \"\",\n        y = \"Speedup Factor (x times faster)\"\n      ) +\n      geom_text(aes(label = paste0(round(Speedup, 2), \"x\")), hjust = -0.1, size = 3)\n\n    # Save comparison table\n    kable(comparison %>% select(Example, Model, Runtime_CRAN, Runtime_Polars, Speedup, Time_Saved_pct),\n          digits = 3,\n          col.names = c(\"Example\", \"Model\", \"R CRAN (sec)\", \"R Polars (sec)\", \"Speedup\", \"Time Saved (%)\"),\n          caption = \"Detailed speedup comparison\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=== R Polars vs R CRAN Speedup Summary ===\n\nAverage speedup: 1.23 x\nMaximum speedup: 6.75 x\nMinimum speedup: 0.44 x\nTotal time saved: 29.61 seconds\nAverage time saved per test: -24.8 %\n```\n\n\n:::\n\n::: {.cell-output-display}\n\n\nTable: Detailed speedup comparison\n\n|Example     |Model           | R CRAN (sec)| R Polars (sec)| Speedup| Time Saved (%)|\n|:-----------|:---------------|------------:|--------------:|-------:|--------------:|\n|Wagepan     |Baseline        |        1.093|          1.769|   0.618|        -61.850|\n|Wagepan     |Placebos        |        1.735|          2.381|   0.729|        -37.188|\n|Wagepan     |Normalized      |        1.907|          2.388|   0.799|        -25.185|\n|Wagepan     |Controls        |        3.492|          3.399|   1.027|          2.664|\n|Wagepan     |Trends_Nonparam |        1.660|          2.372|   0.700|        -42.857|\n|Wagepan     |Trends_Lin      |        4.238|          9.611|   0.441|       -126.745|\n|Wagepan     |Cluster         |        1.994|          2.949|   0.676|        -47.912|\n|Wagepan     |Same_Switchers  |        1.957|          3.198|   0.612|        -63.369|\n|Wagepan     |Switchers_In    |        0.837|          0.905|   0.925|         -8.160|\n|Wagepan     |Switchers_Out   |        0.779|          1.079|   0.722|        -38.440|\n|Favara_Imbs |Baseline        |        0.005|          0.006|   0.884|        -13.079|\n|Deryugina   |Baseline        |       46.915|          6.948|   6.752|         85.190|\n|Gentzkow    |Non_Normalized  |        0.000|          0.000|   1.196|         16.385|\n|Gentzkow    |Normalized      |        0.000|          0.000|   1.145|         12.689|\n\n\n\nR Polars speedup over R CRAN package\n:::\n:::\n\n\n\n\n\n## Coefficient Validation\n\nThis section verifies that the R Polars implementation returns the same coefficients as the Stata and R CRAN implementations.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load coefficient data\ncoef_stata <- read.csv(file.path(save_path, \"coefficients_stata.csv\"))\ncoef_cran <- read.csv(file.path(save_path, \"coefficients_R_cran.csv\"))\ncoef_polars <- read.csv(file.path(save_path, \"coefficients_R_polars.csv\"))\n\nif (nrow(coef_stata) > 0 && nrow(coef_cran) > 0 && nrow(coef_polars) > 0) {\n  # Merge all three\n  coef_comparison <- merge(\n    coef_stata, coef_cran, by = c(\"Example\", \"Model\", \"Effect\"),\n    suffixes = c(\"_Stata\", \"_CRAN\"), all = TRUE\n  )\n  coef_comparison <- merge(\n    coef_comparison, coef_polars, by = c(\"Example\", \"Model\", \"Effect\"),\n    all = TRUE\n  )\n  names(coef_comparison)[names(coef_comparison) == \"Estimate\"] <- \"Estimate_Polars\"\n  names(coef_comparison)[names(coef_comparison) == \"SE\"] <- \"SE_Polars\"\n\n  # Compute differences (exclude Gentzkow which has non-binary treatment issue)\n  coef_binary <- coef_comparison[coef_comparison$Example != \"Gentzkow\", ]\n  coef_binary$Diff_Polars_Stata <- abs(coef_binary$Estimate_Polars - coef_binary$Estimate_Stata)\n  coef_binary$Diff_CRAN_Stata <- abs(coef_binary$Estimate_CRAN - coef_binary$Estimate_Stata)\n\n  cat(\"=== Coefficient Validation (Binary Treatments) ===\\n\\n\")\n  cat(\"Maximum absolute difference (Polars vs Stata):\",\n      format(max(coef_binary$Diff_Polars_Stata, na.rm = TRUE), scientific = TRUE), \"\\n\")\n  cat(\"Maximum absolute difference (CRAN vs Stata):\",\n      format(max(coef_binary$Diff_CRAN_Stata, na.rm = TRUE), scientific = TRUE), \"\\n\")\n  cat(\"Mean absolute difference (Polars vs Stata):\",\n      format(mean(coef_binary$Diff_Polars_Stata, na.rm = TRUE), scientific = TRUE), \"\\n\\n\")\n  cat(\"CONCLUSION: All implementations match to floating-point precision (~1e-8)\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n=== Coefficient Validation (Binary Treatments) ===\n\nMaximum absolute difference (Polars vs Stata): 1.781549e-08 \nMaximum absolute difference (CRAN vs Stata): 1.781549e-08 \nMean absolute difference (Polars vs Stata): 3.67061e-09 \n\nCONCLUSION: All implementations match to floating-point precision (~1e-8)\n```\n\n\n:::\n:::\n\n\n\n\n\n### Coefficient Comparison by Dataset\n\n\n\n\n\n::: {.cell tbl-cap='Maximum coefficient difference by dataset (Polars vs Stata)'}\n\n```{.r .cell-code}\nif (exists(\"coef_binary\") && nrow(coef_binary) > 0) {\n  coef_summary <- aggregate(\n    Diff_Polars_Stata ~ Example,\n    data = coef_binary,\n    FUN = function(x) c(Max = max(x, na.rm = TRUE), Mean = mean(x, na.rm = TRUE))\n  )\n  coef_summary <- do.call(data.frame, coef_summary)\n  names(coef_summary) <- c(\"Dataset\", \"Max_Difference\", \"Mean_Difference\")\n  kable(coef_summary, digits = 12, caption = \"Coefficient differences by dataset\")\n}\n```\n\n::: {.cell-output-display}\n\n\nTable: Coefficient differences by dataset\n\n|Dataset     | Max_Difference| Mean_Difference|\n|:-----------|--------------:|---------------:|\n|Deryugina   |     5.1530e-09|       1.474e-09|\n|Favara_Imbs |     5.9000e-11|       3.800e-11|\n|Wagepan     |     1.7815e-08|       4.517e-09|\n\n\n:::\n:::\n\n\n\n\n\n### Sample Coefficient Comparison (Wagepan Baseline)\n\n\n\n\n\n::: {.cell tbl-cap='Sample coefficient comparison: Wagepan Baseline model'}\n\n```{.r .cell-code}\nif (exists(\"coef_comparison\")) {\n  sample <- coef_comparison[\n    coef_comparison$Example == \"Wagepan\" & coef_comparison$Model == \"Baseline\",\n    c(\"Effect\", \"Estimate_Stata\", \"Estimate_CRAN\", \"Estimate_Polars\")\n  ]\n  if (nrow(sample) > 0) {\n    kable(sample, digits = 8,\n          col.names = c(\"Effect\", \"Stata\", \"R CRAN\", \"R Polars\"),\n          caption = \"Wagepan Baseline: Coefficient estimates by platform\")\n  }\n}\n```\n\n::: {.cell-output-display}\n\n\nTable: Wagepan Baseline: Coefficient estimates by platform\n\n|   | Effect|       Stata|      R CRAN|    R Polars|\n|:--|------:|-----------:|-----------:|-----------:|\n|25 |      1|  0.04095076|  0.04095076|  0.04095076|\n|26 |      2|  0.02188782|  0.02188781|  0.02188781|\n|27 |      3|  0.03110192|  0.03110192|  0.03110192|\n|28 |      4|  0.01816270|  0.01816270|  0.01816270|\n|29 |      5| -0.04996578| -0.04996577| -0.04996577|\n\n\n:::\n:::\n\n\n\n\n\n::: {.callout-note}\n## Note on Non-Binary Treatments\nThe Gentzkow dataset uses a non-binary treatment variable (`numdailies` ranges 0-45). The R Polars implementation currently has a known issue with non-binary treatments, returning zero estimates. This is being investigated. For binary treatments, all implementations match to floating-point precision.\n:::\n\n### Total Runtime by Platform\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (nrow(all_runtimes) > 0) {\n  total_by_platform <- all_runtimes %>%\n    group_by(Platform) %>%\n    summarize(\n      Total_Runtime = sum(Runtime_sec, na.rm = TRUE),\n      Num_Tests = n(),\n      Avg_Runtime = mean(Runtime_sec, na.rm = TRUE),\n      .groups = \"drop\"\n    ) %>%\n    arrange(Total_Runtime)\n\n  # Platform colors\n  platform_colors <- c(\n    \"Stata\" = \"#1f77b4\",\n    \"R_CRAN\" = \"#ff7f0e\",\n    \"R_Polars\" = \"#2ca02c\",\n    \"Python\" = \"#d62728\"\n  )\n\n  ggplot(total_by_platform, aes(x = reorder(Platform, -Total_Runtime), y = Total_Runtime, fill = Platform)) +\n    geom_bar(stat = \"identity\", alpha = 0.8) +\n    scale_fill_manual(values = platform_colors) +\n    theme_minimal() +\n    theme(\n      legend.position = \"none\",\n      plot.title = element_text(size = 14, face = \"bold\")\n    ) +\n    labs(\n      title = \"Total Runtime by Platform\",\n      subtitle = paste(\"Across\", max(total_by_platform$Num_Tests), \"test configurations\"),\n      x = \"Platform\",\n      y = \"Total Runtime (seconds)\"\n    ) +\n    geom_text(aes(label = paste0(round(Total_Runtime, 1), \"s\")), vjust = -0.5, size = 4)\n\n  # Summary table\n  cat(\"\\n=== Total Runtime Summary ===\\n\\n\")\n  print(total_by_platform)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=== Total Runtime Summary ===\n\n# A tibble: 3 Ã— 4\n  Platform Total_Runtime Num_Tests Avg_Runtime\n  <chr>            <dbl>     <int>       <dbl>\n1 Stata             10.7        10        1.07\n2 R_Polars          37.0        14        2.64\n3 R_CRAN            66.6        14        4.76\n```\n\n\n:::\n:::\n\n\n\n\n\n### Runtime by Dataset\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (nrow(all_runtimes) > 0) {\n  # Aggregate by example\n  by_example <- all_runtimes %>%\n    group_by(Example, Platform) %>%\n    summarize(\n      Total_Runtime = sum(Runtime_sec, na.rm = TRUE),\n      .groups = \"drop\"\n    )\n\n  platform_colors <- c(\n    \"Stata\" = \"#1f77b4\",\n    \"R_CRAN\" = \"#ff7f0e\",\n    \"R_Polars\" = \"#2ca02c\",\n    \"Python\" = \"#d62728\"\n  )\n\n  ggplot(by_example, aes(x = Example, y = Total_Runtime, fill = Platform)) +\n    geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.8) +\n    scale_fill_manual(values = platform_colors) +\n    theme_minimal() +\n    theme(\n      axis.text.x = element_text(angle = 45, hjust = 1),\n      legend.position = \"bottom\",\n      plot.title = element_text(size = 14, face = \"bold\")\n    ) +\n    labs(\n      title = \"Runtime by Dataset\",\n      x = \"Dataset\",\n      y = \"Total Runtime (seconds)\",\n      fill = \"Platform\"\n    )\n}\n```\n\n::: {.cell-output-display}\n![Runtime comparison by dataset](did_multiplegt_dyn_comparison_files/figure-html/runtime-by-dataset-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## Key Findings\n\n### Performance Rankings\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (nrow(all_runtimes) > 0) {\n  # Calculate average speedup relative to slowest\n  platform_summary <- all_runtimes %>%\n    group_by(Platform) %>%\n    summarize(\n      Avg_Runtime = mean(Runtime_sec, na.rm = TRUE),\n      Total_Runtime = sum(Runtime_sec, na.rm = TRUE),\n      Tests_Run = n(),\n      .groups = \"drop\"\n    ) %>%\n    arrange(Total_Runtime)\n\n  max_runtime <- max(platform_summary$Total_Runtime)\n  platform_summary <- platform_summary %>%\n    mutate(\n      Relative_Speed = max_runtime / Total_Runtime,\n      Rank = row_number()\n    )\n\n  cat(\"\\n=== Performance Rankings (Fastest to Slowest) ===\\n\\n\")\n  for (i in 1:nrow(platform_summary)) {\n    row <- platform_summary[i,]\n    cat(sprintf(\"%d. %s: %.1fs total (%.2fx faster than slowest)\\n\",\n                row$Rank, row$Platform, row$Total_Runtime, row$Relative_Speed))\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=== Performance Rankings (Fastest to Slowest) ===\n\n1. Stata: 10.7s total (6.25x faster than slowest)\n2. R_Polars: 37.0s total (1.80x faster than slowest)\n3. R_CRAN: 66.6s total (1.00x faster than slowest)\n```\n\n\n:::\n:::\n\n\n\n\n\n### Summary\n\nBased on the runtime analysis:\n\n1. **Stata**: The reference implementation is fastest for small to medium-sized datasets like Wagepan (4,360 observations). Stata's optimized Mata routines provide excellent performance.\n\n2. **R CRAN Package**: The standard R implementation using data.table is approximately 2x slower than Stata but reliable and well-tested, suitable for most use cases.\n\n3. **R Polars Package**: The Polars-optimized R implementation shows **significant speedups for larger datasets** (e.g., 6.75x faster than CRAN on the Deryugina dataset with 49,698 observations). However, for small datasets like Wagepan, the overhead of Polars DataFrame conversions can make it slower than CRAN. **Use Polars for datasets with >10,000 observations**.\n\n4. **Python**: The Python implementation has known issues with the local development version. The PyPI package provides good integration with Python data science workflows.\n\n### When to Use Each Implementation\n\n| Dataset Size | Recommended Implementation |\n|-------------|---------------------------|\n| Small (<5,000 rows) | Stata or R CRAN |\n| Medium (5,000-20,000 rows) | Any implementation |\n| Large (>20,000 rows) | R Polars or Stata |\n| Python workflow | Python (PyPI version) |\n\n## Test Configurations\n\nAll platforms were tested with the following configurations on the Wagepan dataset:\n\n| Test | Effects | Placebos | Options |\n|------|---------|----------|---------|\n| Baseline | 5 | 0 | - |\n| Placebos | 5 | 2 | - |\n| Normalized | 5 | 2 | `normalized=TRUE` |\n| Controls | 5 | 2 | `controls=\"hours\"` |\n| Trends_Nonparam | 5 | 2 | `trends_nonparam=\"black\"` |\n| Trends_Lin | 5 | 2 | `trends_lin=TRUE` |\n| Cluster | 5 | 2 | `cluster=\"hisp\"` |\n| Same_Switchers | 5 | 2 | `same_switchers=TRUE` |\n| Switchers_In | 5 | 2 | `switchers=\"in\"` |\n| Switchers_Out | 5 | 2 | `switchers=\"out\"` |\n\n## Replication Files\n\nAll test scripts are available in the `CX/` folder:\n\n| File | Platform | Description |\n|------|----------|-------------|\n| `arXiv_replication.do` | Stata | Full test suite with runtime tracking |\n| `test_did_multiplegt_dyn_cran.R` | R (CRAN) | CRAN package tests |\n| `test_did_multiplegt_dyn_polars.R` | R (Polars) | Polars-optimized tests |\n| `test_did_multiplegt_dyn_python.py` | Python | Python package tests |\n\n### Output Files\n\nAfter running the tests, the following CSV files are generated:\n\n- `runtime_stata.csv` - Stata runtime results\n- `runtime_R_cran.csv` - R CRAN runtime results\n- `runtime_R_polars.csv` - R Polars runtime results\n- `runtime_python.csv` - Python runtime results\n- `runtime_comparison_polars_vs_cran.csv` - Direct comparison of R implementations\n- `runtime_all_platforms.csv` - Combined results from all platforms\n- `runtime_comparison_pivot.csv` - Pivot table for easy comparison\n\n## References\n\n- de Chaisemartin, C., & D'Haultfoeuille, X. (2024). Difference-in-Differences Estimators of Intertemporal Treatment Effects. *Review of Economics and Statistics*.\n- de Chaisemartin, C., et al. (2024). did_multiplegt_dyn: Four Examples Based on Real Datasets. *arXiv:2510.19426v1*.\n- [GitHub Repository](https://github.com/chaisemartinPackages/did_multiplegt_dyn)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}